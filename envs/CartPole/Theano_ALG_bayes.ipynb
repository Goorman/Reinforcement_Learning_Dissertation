{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano.tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LunarLanding_wrapper():\n",
    "    def __init__(self):\n",
    "        self.state_size = (1, 8)\n",
    "        self.game_title = \"LunarLander-v2\"\n",
    "        self.actions = [\"DO_NOTHING\", \"FIRE_LEFT\", \"FIRE_MAIN\", \"FIRE_RIGHT\"]\n",
    "        self.n_actions = len(self.actions)\n",
    "        try:\n",
    "            self.env = gym.make(self.game_title)\n",
    "        except:\n",
    "            print (\"ERROR : Can't find \" + self.game_title + \" environment.\")\n",
    "            return None\n",
    "        self.env.reset()\n",
    "    \n",
    "    def processState(self, state):\n",
    "        return state.reshape(1, -1)\n",
    "    \n",
    "    def processAction(self, action):\n",
    "        return action\n",
    "    \n",
    "    def make_reset(self):\n",
    "        state = self.env.reset()\n",
    "    \n",
    "        return self.processState(state)\n",
    "    \n",
    "    def make_step(self, action, render = False):\n",
    "        action = self.processAction(action)\n",
    "    \n",
    "        state, ret1, ret2, ret3 = self.env.step(action)\n",
    "    \n",
    "        if render:\n",
    "            self.env.render()\n",
    "    \n",
    "        return self.processState(state), ret1, ret2, ret3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CartPole_wrapper():\n",
    "    def __init__(self):\n",
    "        self.state_size = (1, 4)\n",
    "        self.game_title = \"CartPole-v0\"\n",
    "        self.actions = [\"LEFT\", \"RIGHT\"]\n",
    "        self.n_actions = len(self.actions)\n",
    "        try:\n",
    "            self.env = gym.make(self.game_title)\n",
    "        except:\n",
    "            print (\"ERROR : Can't find \" + self.game_title + \" environment.\")\n",
    "            return None\n",
    "        self.env.reset()\n",
    "    \n",
    "    def processState(self, state):\n",
    "        return state.reshape(1, -1)\n",
    "    \n",
    "    def processAction(self, action):\n",
    "        return action\n",
    "    \n",
    "    def make_reset(self):\n",
    "        state = self.env.reset()\n",
    "    \n",
    "        return self.processState(state)\n",
    "    \n",
    "    def make_step(self, action, render = False):\n",
    "        action = self.processAction(action)\n",
    "    \n",
    "        state, ret1, ret2, ret3 = self.env.step(action)\n",
    "    \n",
    "        if render:\n",
    "            self.env.render()\n",
    "    \n",
    "        return self.processState(state), ret1, ret2, ret3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AVQ_nn():\n",
    "    def __init__(self, channels_number = 4, image_shape = (1, 8), n_actions = 4, grad_clipping = 10, lr = 0.0001, h = 50, alpha = 25):\n",
    "        self.input_var = T.tensor4('input')\n",
    "        \n",
    "        self.n_actions = n_actions\n",
    "        self.build_network(channels_number, image_shape)\n",
    "        self.build_AVQ(grad_clipping, lr, h, alpha)\n",
    "        self.compile_network()\n",
    "        \n",
    "    def build_network(self, channels_number, image_shape):\n",
    "        self.l1 = lasagne.layers.InputLayer(shape=(None, channels_number, image_shape[0], image_shape[1]), \n",
    "                                            input_var = self.input_var)\n",
    "        self.l2 = lasagne.layers.DenseLayer(self.l1, 40, nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "        self.l3 = lasagne.layers.DenseLayer(self.l2, 40, nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "        self.outlayer = lasagne.layers.DenseLayer(self.l3, 50, nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    def build_AVQ(self, grad_clipping, lr, h, alpha):\n",
    "        self.l_advantage = lasagne.layers.DenseLayer(self.outlayer, self.n_actions)\n",
    "        self.l_value = lasagne.layers.DenseLayer(self.outlayer, 1)\n",
    "        self.l_varq = lasagne.layers.DenseLayer(self.outlayer, self.n_actions, nonlinearity=lasagne.nonlinearities.softplus)\n",
    "        \n",
    "        self.advantage, self.value, self.varq = lasagne.layers.get_output([self.l_advantage, self.l_value, self.l_varq])\n",
    "\n",
    "        self.average_advantage = T.mean(self.advantage, keepdims = True, axis = 1)\n",
    "        \n",
    "#        self.Q = self.advantage + self.value - self.average_advantage\n",
    "        self.Q = self.advantage\n",
    "        self.predict = T.argmax(self.Q, axis = 1)\n",
    "        \n",
    "        self.targetQ = T.fvector('targetQ')\n",
    "        self.actions = T.ivector('actions')\n",
    "        self.actions_onehot = T.extra_ops.to_one_hot(self.actions, self.n_actions, dtype=np.float32)\n",
    "        \n",
    "        self.Q0 = T.sum(self.Q * self.actions_onehot, axis = 1)\n",
    "        self.varQ0 = T.sum(self.varq * self.actions_onehot, axis = 1)\n",
    "        \n",
    "        self.Q1 = self.Q0 + (self.targetQ - self.Q0) / (h + 1)\n",
    "        self.varQ1 = (h * (alpha - 1)) / ((h + 1) * (alpha - 0.5)) * \\\n",
    "                     (self.varQ0 + T.sqr(self.targetQ - self.Q0) / (2 * (h+1) * (alpha - 1)))\n",
    "        \n",
    "        self.td_error = T.mean(T.sqr(self.Q1 - self.Q0))\n",
    "        self.var_error = T.mean(T.sqr(self.varQ1 - self.varQ0))\n",
    "        self.loss = self.td_error + self.var_error\n",
    "        \n",
    "        params = self.get_all_params()\n",
    "        self.all_grads = T.grad(self.loss, params)\n",
    "        self.scaled_grads = lasagne.updates.total_norm_constraint(self.all_grads, grad_clipping)\n",
    "        self.updates = lasagne.updates.adam(self.scaled_grads, params, learning_rate=lr)\n",
    "        \n",
    "    def compile_network(self):\n",
    "        self.Qout_fn = theano.function([self.input_var], self.Q)\n",
    "        self.actionpred_fn = theano.function([self.input_var], self.predict)\n",
    "        self.train_fn = theano.function([self.input_var, self.targetQ, self.actions], [self.loss, self.Q1, self.varQ1], updates = self.updates)\n",
    "        self.var_fn = theano.function([self.input_var], self.varq)\n",
    "    \n",
    "    def get_all_params(self):\n",
    "#        return lasagne.layers.get_all_params([self.l_advantage, self.l_value], trainable = True)\n",
    "        return lasagne.layers.get_all_params([self.l_advantage, self.l_varq], trainable = True)\n",
    "    \n",
    "    def get_all_params_values(self):\n",
    "#        return lasagne.layers.get_all_param_values([self.l_advantage, self.l_value], trainable = True)\n",
    "        return lasagne.layers.get_all_param_values([self.l_advantage, self.l_varq], trainable = True)\n",
    "    \n",
    "    def set_all_params_values(self, values):\n",
    "#        return lasagne.layers.set_all_param_values([self.l_advantage, self.l_value], values, trainable = True)\n",
    "        return lasagne.layers.set_all_param_values([self.l_advantage, self.l_varq], values, trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 10000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self, experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self, size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class window_aggregator():\n",
    "    def __init__(self, window_length, state_shape):\n",
    "        self.state_shape = state_shape\n",
    "        self.window_length = window_length\n",
    "        \n",
    "        assert len(self.state_shape) == 2\n",
    "        assert self.window_length >= 1\n",
    "        \n",
    "        self.start_aggregator_shape = (window_length, state_shape[0], state_shape[1])\n",
    "                                             \n",
    "        self.aggregator = np.zeros(self.start_aggregator_shape)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.aggregator = np.zeros(self.start_aggregator_shape)\n",
    "                                       \n",
    "    def add_state(self, state):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        self.aggregator = np.append(self.aggregator, state, axis = 0)\n",
    "    \n",
    "    def get_window(self):\n",
    "        return self.aggregator[-self.window_length:,:,:]                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class egreedy_agent():\n",
    "    def __init__(self, n_actions, actionpred_fn, startE = 1, endE = 0.1, anneling_steps = 50000):\n",
    "        self.startE = startE\n",
    "        self.endE = endE\n",
    "        self.anneling_steps = anneling_steps\n",
    "        self.stepE = (self.startE - self.endE) / self.anneling_steps\n",
    "        self.n_actions = n_actions\n",
    "        self.actionpred_fn = actionpred_fn\n",
    "    \n",
    "    def choose_action(self, state, current_step):\n",
    "        if current_step > self.anneling_steps:\n",
    "            epsilon = self.endE\n",
    "        else:\n",
    "            epsilon = self.startE - self.stepE * current_step\n",
    "        \n",
    "        if np.random.rand(1) < epsilon:\n",
    "            a = np.random.randint(0, self.n_actions)\n",
    "        else:\n",
    "            a = self.actionpred_fn(np.expand_dims(state, axis = 0))[0]\n",
    "            \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class boltzman_agent:\n",
    "    def __init__(self, n_actions, Qout_fn, startT = 1000, endT = 0.1, anneling_steps = 50000):\n",
    "        self.startT = startT\n",
    "        self.endT = endT\n",
    "        self.anneling_steps = anneling_steps\n",
    "        self.logstep = (np.log(startT) - np.log(endT)) / anneling_steps\n",
    "        self.n_actions = n_actions\n",
    "        self.Qout_fn = Qout_fn\n",
    "    \n",
    "    def choose_action(self, state, current_step):\n",
    "        scores = self.Qout_fn(np.expand_dims(state, axis = 0))[0]\n",
    "        if current_step > self.anneling_steps:\n",
    "            exponents = np.exp((scores - np.max(scores)) / self.endT)\n",
    "        else:\n",
    "            current_temp = self.startT / np.exp(self.logstep * current_step)\n",
    "            exponents = np.exp((scores - np.max(scores)) / current_temp)\n",
    "        probs = exponents / np.sum(exponents)\n",
    "        return np.random.choice(self.n_actions, p = probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class bayes_agent():\n",
    "    def __init__(self, n_actions, actionpred_fn, var_fn, startE = 1, endE = 0.1, anneling_steps = 50000):\n",
    "        self.startE = startE\n",
    "        self.endE = endE\n",
    "        self.anneling_steps = anneling_steps\n",
    "        self.stepE = (self.startE - self.endE) / self.anneling_steps\n",
    "        self.n_actions = n_actions\n",
    "        self.actionpred_fn = actionpred_fn\n",
    "        self.var_fn = var_fn\n",
    "    \n",
    "    def choose_action(self, state, current_step):\n",
    "        if current_step > self.anneling_steps:\n",
    "            epsilon = self.endE\n",
    "        else:\n",
    "            epsilon = self.startE - self.stepE * current_step\n",
    "        \n",
    "        if np.random.rand(1) < epsilon:\n",
    "            scores = self.var_fn(np.expand_dims(state, axis = 0))\n",
    "            a = np.argmax(scores)\n",
    "        else:\n",
    "            a = self.actionpred_fn(np.expand_dims(state, axis = 0))[0]\n",
    "            \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DDQL():\n",
    "    def __init__(self, lparams, env, agent = {\"agent\":\"egreedy\", \"params\":{}}):\n",
    "        self.grad_clip = lparams[\"grad_clipping\"]\n",
    "        self.lr = lparams[\"learning_rate\"]\n",
    "        self.window_size = lparams[\"window_size\"]\n",
    "        self.batch_size = lparams[\"batch_size\"]\n",
    "        self.gamma = lparams[\"gamma\"]\n",
    "        self.h = lparams[\"lambda\"]\n",
    "        self.alpha = lparams[\"alpha\"]\n",
    "        self.MQN_updatefreq = lparams[\"MQN_updatefreq\"]\n",
    "        self.TQN_updatefreq = lparams[\"TQN_updatefreq\"]\n",
    "        self.TQN_updaterate = lparams[\"TQN_updaterate\"]\n",
    "        self.print_freq = lparams[\"print_freq\"]\n",
    "        self.pretrain_steps = lparams[\"pretrain_steps\"]\n",
    "        self.buffer_size = lparams[\"buffer_size\"]\n",
    "        self.pretrain_over = False\n",
    "        \n",
    "        self.env = env\n",
    "        AVQ_params = [self.window_size, self.env.state_size, self.env.n_actions, \n",
    "                      self.grad_clip, self.lr, self.h, self.alpha]\n",
    "        self.mainQN = AVQ_nn(*AVQ_params)\n",
    "        self.targetQN = AVQ_nn(*AVQ_params)\n",
    "\n",
    "        self.jList = []\n",
    "        self.rList = []\n",
    "        self.total_steps = 0\n",
    "        \n",
    "        self.window = window_aggregator(self.window_size, self.env.state_size)\n",
    "        self.experience_storage = experience_buffer(self.buffer_size)\n",
    "        self.agent = self.getAgent(agent[\"agent\"], agent[\"params\"])\n",
    "            \n",
    "    def getAgent(self, agent, agentparams):\n",
    "        if agent == \"egreedy\":\n",
    "            return egreedy_agent(self.env.n_actions, self.mainQN.actionpred_fn, **agentparams)\n",
    "        elif agent == \"boltzman\":\n",
    "            return boltzman_agent(self.env.n_actions, self.mainQN.Qout_fn, **agentparams)\n",
    "        elif agent == \"bayes\":\n",
    "            return bayes_agent(self.env.n_actions, self.mainQN.actionpred_fn, self.mainQN.var_fn, **agentparams)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown agent\")\n",
    "            \n",
    "    def updateTarget(self, completeupdate = False):\n",
    "        if completeupdate:\n",
    "            self.targetQN.set_all_params_values(self.mainQN.get_all_params_values())\n",
    "        else:\n",
    "            targetparams = self.targetQN.get_all_params_values()\n",
    "            mainparams = self.mainQN.get_all_params_values()\n",
    "            ur = self.TQN_updaterate\n",
    "        \n",
    "            assert len(targetparams) == len(mainparams)\n",
    "            for k in range(0, len(targetparams)):\n",
    "                targetparams[k] = targetparams[k] * (1.0 - ur) + mainparams[k] * ur\n",
    "        \n",
    "            self.targetQN.set_all_params_values(targetparams)\n",
    "\n",
    "    def train(self, num_episodes, frame_limit, render = True):\n",
    "        self.updateTarget(True)\n",
    "        self.window.reset()\n",
    "            \n",
    "        for episode_num in tqdm_notebook(range(num_episodes), desc = \"RL train\"):\n",
    "            state = self.env.make_reset()\n",
    "            self.window.add_state(state)\n",
    "            window_state = self.window.get_window()\n",
    "            episode_rewards = np.zeros(frame_limit)\n",
    "                \n",
    "            for iteration in xrange(0, frame_limit):\n",
    "                action = self.agent.choose_action(window_state, self.total_steps)\n",
    "                new_state, reward, gameover, _ = self.env.make_step(action, render)\n",
    "                self.window.add_state(new_state)\n",
    "                new_window_state = self.window.get_window()\n",
    "                self.experience_storage.add(np.reshape(np.array([window_state, action, reward, new_window_state, gameover]),[1,5]))\n",
    "                episode_rewards[iteration] = reward\n",
    "                \n",
    "                if self.pretrain_over:\n",
    "                    self.total_steps += 1\n",
    "                \n",
    "                    if self.total_steps % (self.TQN_updatefreq) == 0:\n",
    "                        self.updateTarget()\n",
    "                \n",
    "                    if self.total_steps % (self.MQN_updatefreq) == 0:\n",
    "                        train_batch = self.experience_storage.sample(self.batch_size)\n",
    "                        old_state_batch = np.stack(train_batch[:,0])\n",
    "                        new_state_batch = np.stack(train_batch[:,3])\n",
    "                        action_vector = (train_batch[:,1]).astype(np.int32)\n",
    "                        end_multiplier = -(train_batch[:,4] - 1)\n",
    "                        rewards_vector = train_batch[:,2]\n",
    "                        \n",
    "                        Q1 = self.mainQN.actionpred_fn(new_state_batch)   \n",
    "                        Q2 = self.targetQN.Qout_fn(new_state_batch)\n",
    "                        \n",
    "                        \n",
    "                        doubleQ = Q2[range(self.batch_size),Q1]\n",
    "                        targetQ = (rewards_vector + (self.gamma * doubleQ * end_multiplier)).astype(np.float32)\n",
    "                        loss, Qval, Qvar = self.mainQN.train_fn(old_state_batch, targetQ, action_vector)\n",
    "                         \n",
    "                else:\n",
    "                    self.pretrain_steps -= 1;\n",
    "                    if self.pretrain_steps <= 0:\n",
    "                        self.pretrain_over = True\n",
    "                        \n",
    "                state = new_state\n",
    "                window_state = new_window_state\n",
    "            \n",
    "                if gameover:\n",
    "                    self.window.reset()\n",
    "                    break\n",
    "    \n",
    "            total_reward = np.sum(episode_rewards)\n",
    "            self.jList.append(iteration)\n",
    "            self.rList.append(total_reward)\n",
    "            if len(self.rList) % self.print_freq == 0:\n",
    "                tqdm.write(\" \".join([\"========= Episode\", str(episode_num), \"================================================\"]))\n",
    "                tqdm.write(\" \".join([\"Total steps:\", str(self.total_steps)]))\n",
    "                tqdm.write(\" \".join([\"Episode rewards, last 10:\", str(self.rList[-10:])]))\n",
    "                tqdm.write(\" \".join([\"Mean over last\", str(self.print_freq), \"episodes:\", str(np.mean(self.rList[-self.print_freq:]))]))\n",
    "                tqdm.write(\" \".join([\"Episode lengths, last 10:\", str(self.jList[-10:])]))\n",
    "                tqdm.write(\"===================================================================\" + \"=\" * len(str(episode_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rewards(ddqlmodel, meanwindow = 250):\n",
    "    rlist = [ddqlmodel.rList[0]] * meanwindow + ddqlmodel.rList\n",
    "    x = np.cumsum(ddqlmodel.jList)\n",
    "    y = [np.mean(rlist[k:k+meanwindow]) for k in range(len(rlist) - meanwindow)]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-15 18:41:51,322] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "#llenv = LunarLanding_wrapper()\n",
    "cp_env = CartPole_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lparams = {\"grad_clipping\" : 50,\n",
    "           \"learning_rate\" : 0.005,\n",
    "           \"window_size\" : 1,\n",
    "           \"batch_size\" : 8,\n",
    "           \"buffer_size\" : 128,\n",
    "           \"gamma\" : 0.98,\n",
    "           \"lambda\": 4,\n",
    "           \"alpha\": 2,\n",
    "           \"MQN_updatefreq\" : 1,\n",
    "           \"TQN_updatefreq\" : 4,\n",
    "           \"TQN_updaterate\" : 0.2,\n",
    "           \"print_freq\" : 500,\n",
    "           \"pretrain_steps\" : 5000,\n",
    "           \"render\" : False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "egreedyagentinfo = {\"agent\" : \"egreedy\",\n",
    "                    \"params\" : {\"startE\": 0.5,\n",
    "                                \"endE\" : 0.1,\n",
    "                                \"anneling_steps\":1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boltzmanagentinfo = {\"agent\" : \"boltzman\",\n",
    "                     \"params\" : {\"startT\": 10,\n",
    "                                 \"endT\" : 1,\n",
    "                                 \"anneling_steps\":10000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesagentinfo = {\"agent\" : \"bayes\",\n",
    "                    \"params\" : {\"startE\": 0.5,\n",
    "                                \"endE\" : 0.1,\n",
    "                                \"anneling_steps\":1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_experiment(ddql, ddql_init_params, ddql_train_params, experiment_num = 5):\n",
    "    ddql_list = [ddql(**ddql_init_params) for k in range(experiment_num)]\n",
    "    \n",
    "    for k in range(experiment_num):\n",
    "        ddql_list[k].train(**ddql_train_params)\n",
    "        \n",
    "    return ddql_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddql_bayes_params = {\"lparams\":lparams, \"env\":cp_env, \"agent\":bayesagentinfo}\n",
    "\n",
    "ddql_train_params = {\"num_episodes\":2500, \"frame_limit\":500, \"render\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 0\n",
      "Episode rewards, last 10: [10.0, 9.0, 10.0, 9.0, 9.0, 9.0, 10.0, 10.0, 9.0, 10.0]\n",
      "Mean over last 500 episodes: 9.746\n",
      "Episode lengths, last 10: [9, 8, 9, 8, 8, 8, 9, 9, 8, 9]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 87959\n",
      "Episode rewards, last 10: [197.0, 207.0, 233.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 176.172\n",
      "Episode lengths, last 10: [196, 206, 232, 499, 499, 499, 499, 499, 499, 499]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 200131\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 500.0, 500.0, 17.0, 14.0, 49.0, 14.0, 127.0]\n",
      "Mean over last 500 episodes: 224.344\n",
      "Episode lengths, last 10: [499, 499, 499, 499, 499, 16, 13, 48, 13, 126]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 300938\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 330.0, 55.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 201.614\n",
      "Episode lengths, last 10: [499, 499, 499, 329, 54, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 397864\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 197.0, 51.0, 35.0]\n",
      "Mean over last 500 episodes: 193.852\n",
      "Episode lengths, last 10: [499, 499, 499, 499, 499, 499, 499, 196, 50, 34]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 3272\n",
      "Episode rewards, last 10: [9.0, 11.0, 9.0, 16.0, 11.0, 12.0, 11.0, 9.0, 10.0, 12.0]\n",
      "Mean over last 500 episodes: 16.544\n",
      "Episode lengths, last 10: [8, 10, 8, 15, 10, 11, 10, 8, 9, 11]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 46110\n",
      "Episode rewards, last 10: [150.0, 158.0, 138.0, 147.0, 272.0, 500.0, 246.0, 82.0, 191.0, 156.0]\n",
      "Mean over last 500 episodes: 85.676\n",
      "Episode lengths, last 10: [149, 157, 137, 146, 271, 499, 245, 81, 190, 155]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 158692\n",
      "Episode rewards, last 10: [114.0, 17.0, 26.0, 26.0, 11.0, 81.0, 100.0, 380.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 225.164\n",
      "Episode lengths, last 10: [113, 16, 25, 25, 10, 80, 99, 379, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 249613\n",
      "Episode rewards, last 10: [275.0, 125.0, 13.0, 11.0, 12.0, 11.0, 28.0, 13.0, 72.0, 500.0]\n",
      "Mean over last 500 episodes: 181.842\n",
      "Episode lengths, last 10: [274, 124, 12, 10, 11, 10, 27, 12, 71, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 338631\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 500.0, 400.0, 51.0, 24.0, 363.0, 16.0, 227.0]\n",
      "Mean over last 500 episodes: 178.036\n",
      "Episode lengths, last 10: [499, 499, 499, 499, 399, 50, 23, 362, 15, 226]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 40989\n",
      "Episode rewards, last 10: [165.0, 180.0, 281.0, 468.0, 65.0, 264.0, 121.0, 111.0, 13.0, 143.0]\n",
      "Mean over last 500 episodes: 91.978\n",
      "Episode lengths, last 10: [164, 179, 280, 467, 64, 263, 120, 110, 12, 142]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 146846\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 379.0, 71.0, 48.0, 13.0]\n",
      "Mean over last 500 episodes: 211.714\n",
      "Episode lengths, last 10: [499, 499, 499, 499, 499, 499, 378, 70, 47, 12]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 249578\n",
      "Episode rewards, last 10: [72.0, 15.0, 71.0, 56.0, 500.0, 500.0, 500.0, 258.0, 500.0, 216.0]\n",
      "Mean over last 500 episodes: 205.464\n",
      "Episode lengths, last 10: [71, 14, 70, 55, 499, 499, 499, 257, 499, 215]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 353937\n",
      "Episode rewards, last 10: [50.0, 249.0, 12.0, 500.0, 500.0, 500.0, 500.0, 500.0, 299.0, 140.0]\n",
      "Mean over last 500 episodes: 208.718\n",
      "Episode lengths, last 10: [49, 248, 11, 499, 499, 499, 499, 499, 298, 139]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 462026\n",
      "Episode rewards, last 10: [59.0, 308.0, 373.0, 238.0, 160.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 216.178\n",
      "Episode lengths, last 10: [58, 307, 372, 237, 159, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 33343\n",
      "Episode rewards, last 10: [500.0, 500.0, 209.0, 84.0, 31.0, 176.0, 437.0, 52.0, 30.0, 48.0]\n",
      "Mean over last 500 episodes: 76.686\n",
      "Episode lengths, last 10: [499, 499, 208, 83, 30, 175, 436, 51, 29, 47]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 150037\n",
      "Episode rewards, last 10: [23.0, 20.0, 94.0, 198.0, 97.0, 146.0, 133.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 233.388\n",
      "Episode lengths, last 10: [22, 19, 93, 197, 96, 145, 132, 499, 499, 499]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 266628\n",
      "Episode rewards, last 10: [80.0, 81.0, 73.0, 44.0, 364.0, 129.0, 24.0, 16.0, 116.0, 176.0]\n",
      "Mean over last 500 episodes: 233.182\n",
      "Episode lengths, last 10: [79, 80, 72, 43, 363, 128, 23, 15, 115, 175]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 384455\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 337.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 235.654\n",
      "Episode lengths, last 10: [499, 499, 499, 336, 499, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 497995\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 280.0, 164.0, 103.0, 18.0, 22.0, 14.0, 128.0]\n",
      "Mean over last 500 episodes: 227.08\n",
      "Episode lengths, last 10: [499, 499, 499, 279, 163, 102, 17, 21, 13, 127]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 1977\n",
      "Episode rewards, last 10: [165.0, 215.0, 166.0, 217.0, 65.0, 28.0, 38.0, 34.0, 9.0, 10.0]\n",
      "Mean over last 500 episodes: 13.954\n",
      "Episode lengths, last 10: [164, 214, 165, 216, 64, 27, 37, 33, 8, 9]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 87065\n",
      "Episode rewards, last 10: [183.0, 171.0, 310.0, 176.0, 257.0, 139.0, 167.0, 147.0, 153.0, 215.0]\n",
      "Mean over last 500 episodes: 170.176\n",
      "Episode lengths, last 10: [182, 170, 309, 175, 256, 138, 166, 146, 152, 214]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 193689\n",
      "Episode rewards, last 10: [351.0, 143.0, 64.0, 29.0, 304.0, 90.0, 129.0, 154.0, 93.0, 338.0]\n",
      "Mean over last 500 episodes: 213.248\n",
      "Episode lengths, last 10: [350, 142, 63, 28, 303, 89, 128, 153, 92, 337]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 300819\n",
      "Episode rewards, last 10: [15.0, 14.0, 13.0, 19.0, 17.0, 17.0, 15.0, 13.0, 14.0, 14.0]\n",
      "Mean over last 500 episodes: 214.26\n",
      "Episode lengths, last 10: [14, 13, 12, 18, 16, 16, 14, 12, 13, 13]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 398499\n",
      "Episode rewards, last 10: [22.0, 21.0, 48.0, 37.0, 60.0, 15.0, 42.0, 147.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 195.36\n",
      "Episode lengths, last 10: [21, 20, 47, 36, 59, 14, 41, 146, 499, 499]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 50492\n",
      "Episode rewards, last 10: [232.0, 195.0, 204.0, 152.0, 155.0, 156.0, 152.0, 174.0, 225.0, 280.0]\n",
      "Mean over last 500 episodes: 110.984\n",
      "Episode lengths, last 10: [231, 194, 203, 151, 154, 155, 151, 173, 224, 279]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 152126\n",
      "Episode rewards, last 10: [42.0, 15.0, 14.0, 11.0, 15.0, 20.0, 17.0, 110.0, 158.0, 500.0]\n",
      "Mean over last 500 episodes: 203.268\n",
      "Episode lengths, last 10: [41, 14, 13, 10, 14, 19, 16, 109, 157, 499]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 255197\n",
      "Episode rewards, last 10: [89.0, 500.0, 500.0, 407.0, 163.0, 345.0, 306.0, 490.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 206.142\n",
      "Episode lengths, last 10: [88, 499, 499, 406, 162, 344, 305, 489, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 351074\n",
      "Episode rewards, last 10: [15.0, 108.0, 32.0, 500.0, 134.0, 500.0, 113.0, 110.0, 123.0, 113.0]\n",
      "Mean over last 500 episodes: 191.754\n",
      "Episode lengths, last 10: [14, 107, 31, 499, 133, 499, 112, 109, 122, 112]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 436545\n",
      "Episode rewards, last 10: [364.0, 225.0, 89.0, 330.0, 230.0, 202.0, 165.0, 178.0, 186.0, 168.0]\n",
      "Mean over last 500 episodes: 170.942\n",
      "Episode lengths, last 10: [363, 224, 88, 329, 229, 201, 164, 177, 185, 167]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 0\n",
      "Episode rewards, last 10: [9.0, 9.0, 10.0, 8.0, 10.0, 12.0, 9.0, 9.0, 10.0, 9.0]\n",
      "Mean over last 500 episodes: 9.542\n",
      "Episode lengths, last 10: [8, 8, 9, 7, 9, 11, 8, 8, 9, 8]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 68061\n",
      "Episode rewards, last 10: [11.0, 20.0, 19.0, 36.0, 18.0, 33.0, 9.0, 31.0, 40.0, 500.0]\n",
      "Mean over last 500 episodes: 136.58\n",
      "Episode lengths, last 10: [10, 19, 18, 35, 17, 32, 8, 30, 39, 499]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 151942\n",
      "Episode rewards, last 10: [360.0, 128.0, 170.0, 103.0, 15.0, 102.0, 91.0, 74.0, 79.0, 16.0]\n",
      "Mean over last 500 episodes: 167.762\n",
      "Episode lengths, last 10: [359, 127, 169, 102, 14, 101, 90, 73, 78, 15]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 248696\n",
      "Episode rewards, last 10: [23.0, 22.0, 16.0, 16.0, 18.0, 102.0, 11.0, 24.0, 331.0, 466.0]\n",
      "Mean over last 500 episodes: 193.508\n",
      "Episode lengths, last 10: [22, 21, 15, 15, 17, 101, 10, 23, 330, 465]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 351277\n",
      "Episode rewards, last 10: [38.0, 20.0, 144.0, 69.0, 44.0, 37.0, 38.0, 50.0, 76.0, 58.0]\n",
      "Mean over last 500 episodes: 205.162\n",
      "Episode lengths, last 10: [37, 19, 143, 68, 43, 36, 37, 49, 75, 57]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 1166\n",
      "Episode rewards, last 10: [28.0, 10.0, 13.0, 25.0, 15.0, 68.0, 120.0, 59.0, 10.0, 14.0]\n",
      "Mean over last 500 episodes: 12.332\n",
      "Episode lengths, last 10: [27, 9, 12, 24, 14, 67, 119, 58, 9, 13]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 96822\n",
      "Episode rewards, last 10: [17.0, 12.0, 54.0, 145.0, 157.0, 302.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 191.312\n",
      "Episode lengths, last 10: [16, 11, 53, 144, 156, 301, 499, 499, 499, 499]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 192535\n",
      "Episode rewards, last 10: [500.0, 71.0, 69.0, 400.0, 59.0, 500.0, 117.0, 98.0, 335.0, 99.0]\n",
      "Mean over last 500 episodes: 191.426\n",
      "Episode lengths, last 10: [499, 70, 68, 399, 58, 499, 116, 97, 334, 98]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 313975\n",
      "Episode rewards, last 10: [493.0, 131.0, 104.0, 224.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 242.88\n",
      "Episode lengths, last 10: [492, 130, 103, 223, 499, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 413483\n",
      "Episode rewards, last 10: [79.0, 107.0, 58.0, 27.0, 20.0, 69.0, 53.0, 48.0, 48.0, 47.0]\n",
      "Mean over last 500 episodes: 199.016\n",
      "Episode lengths, last 10: [78, 106, 57, 26, 19, 68, 52, 47, 47, 46]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 2776\n",
      "Episode rewards, last 10: [9.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0]\n",
      "Mean over last 500 episodes: 15.552\n",
      "Episode lengths, last 10: [8, 9, 8, 8, 8, 8, 8, 8, 9, 9]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 7511\n",
      "Episode rewards, last 10: [8.0, 10.0, 9.0, 10.0, 9.0, 10.0, 9.0, 9.0, 10.0, 9.0]\n",
      "Mean over last 500 episodes: 9.47\n",
      "Episode lengths, last 10: [7, 9, 8, 9, 8, 9, 8, 8, 9, 8]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 12435\n",
      "Episode rewards, last 10: [9.0, 12.0, 9.0, 11.0, 9.0, 9.0, 9.0, 11.0, 10.0, 9.0]\n",
      "Mean over last 500 episodes: 9.848\n",
      "Episode lengths, last 10: [8, 11, 8, 10, 8, 8, 8, 10, 9, 8]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 17243\n",
      "Episode rewards, last 10: [11.0, 11.0, 10.0, 10.0, 10.0, 9.0, 9.0, 10.0, 9.0, 10.0]\n",
      "Mean over last 500 episodes: 9.616\n",
      "Episode lengths, last 10: [10, 10, 9, 9, 9, 8, 8, 9, 8, 9]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 22135\n",
      "Episode rewards, last 10: [10.0, 12.0, 9.0, 10.0, 9.0, 10.0, 9.0, 9.0, 10.0, 10.0]\n",
      "Mean over last 500 episodes: 9.784\n",
      "Episode lengths, last 10: [9, 11, 8, 9, 8, 9, 8, 8, 9, 9]\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 28500\n",
      "Episode rewards, last 10: [88.0, 68.0, 86.0, 97.0, 87.0, 100.0, 115.0, 128.0, 93.0, 172.0]\n",
      "Mean over last 500 episodes: 67.0\n",
      "Episode lengths, last 10: [87, 67, 85, 96, 86, 99, 114, 127, 92, 171]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 124321\n",
      "Episode rewards, last 10: [105.0, 121.0, 131.0, 118.0, 149.0, 143.0, 250.0, 211.0, 31.0, 139.0]\n",
      "Mean over last 500 episodes: 191.642\n",
      "Episode lengths, last 10: [104, 120, 130, 117, 148, 142, 249, 210, 30, 138]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 224104\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 246.0, 115.0, 70.0, 87.0, 72.0, 24.0, 184.0]\n",
      "Mean over last 500 episodes: 199.566\n",
      "Episode lengths, last 10: [499, 499, 499, 245, 114, 69, 86, 71, 23, 183]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 326997\n",
      "Episode rewards, last 10: [129.0, 500.0, 500.0, 500.0, 500.0, 301.0, 11.0, 30.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 205.786\n",
      "Episode lengths, last 10: [128, 499, 499, 499, 499, 300, 10, 29, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 440153\n",
      "Episode rewards, last 10: [500.0, 46.0, 500.0, 500.0, 183.0, 134.0, 89.0, 33.0, 32.0, 51.0]\n",
      "Mean over last 500 episodes: 226.312\n",
      "Episode lengths, last 10: [499, 45, 499, 499, 182, 133, 88, 32, 31, 50]\n",
      "=======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = produce_experiment(DDQL, ddql_bayes_params, ddql_train_params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(ddql_res, window = 100, std_coef = 0.2, results_over = 1000):\n",
    "    res_lists = [k.rList for k in ddql_res]\n",
    "    res_lists = np.array(res_lists)\n",
    "    pd.DataFrame(data = res_lists)\n",
    "    mean = res_lists.mean(axis = 0)\n",
    "    std = res_lists.std(axis = 0)\n",
    "    rol_mean = np.nan_to_num(pd.Series(mean).rolling(window = window).mean())\n",
    "    rol_std = np.nan_to_num(pd.Series(std).rolling(window = window).mean())\n",
    "    plt.figure()\n",
    "    index = np.arange(len(rol_mean))\n",
    "    plt.plot(index, rol_mean)\n",
    "    plt.fill_between(index, rol_mean-std_coef*rol_std, rol_mean+std_coef*rol_std, color='b', alpha=0.1)\n",
    "    return max(rol_mean[0:results_over]), rol_mean[0:results_over].mean(), pd.DataFrame(data = res_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIapcljoGYZhqpz/B6097v2BBNKpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131fa5d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayes_max, bayes_auc, bayes_df = plot_results(res, 100, 0.2)\n",
    "plt.savefig(\"bayes_cp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.35 91.645872\n"
     ]
    }
   ],
   "source": [
    "print bayes_max, bayes_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_df.to_csv(\"bayes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "widgets": {
   "state": {
    "3c204b607cb14286bbd6ee9c117cf423": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "4743bea11db3430c9703fb62fb6ec2ea": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "6d2173e809654f18b5cbc542e36d2e9d": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "81a8212689e04224b39ade0449c5325f": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "86f2cbc45bc1494fb7e409c1201665cc": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "8eff0a0ee4754c79945f2e7afa2e0dd2": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "960a61dff50f415d9f8536217ba9ee5b": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "9ddd99d3753f4045b15116f6f05e6414": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "b47bee3eb60f49a98dd1d5a1347fb1d6": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "ccffe7e048d1485eafe37c8ddd1c938c": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "cffb3e1d70aa4e95af372253ad808202": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "d659bd36378448b0bccc92454ebbb14c": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "d9f47c7ba7914cf0bbe8bf046a0dd80e": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "ef486d933aa443d6808757305396c962": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "f81342256f2f46de871c550fbade9606": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
