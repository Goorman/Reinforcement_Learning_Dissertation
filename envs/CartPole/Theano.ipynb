{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano.tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LunarLanding_wrapper():\n",
    "    def __init__(self):\n",
    "        self.state_size = (1, 8)\n",
    "        self.game_title = \"LunarLander-v2\"\n",
    "        self.actions = [\"DO_NOTHING\", \"FIRE_LEFT\", \"FIRE_MAIN\", \"FIRE_RIGHT\"]\n",
    "        self.n_actions = len(self.actions)\n",
    "        try:\n",
    "            self.env = gym.make(self.game_title)\n",
    "        except:\n",
    "            print (\"ERROR : Can't find \" + self.game_title + \" environment.\")\n",
    "            return None\n",
    "        self.env.reset()\n",
    "    \n",
    "    def processState(self, state):\n",
    "        return state.reshape(1, -1)\n",
    "    \n",
    "    def processAction(self, action):\n",
    "        return action\n",
    "    \n",
    "    def make_reset(self):\n",
    "        state = self.env.reset()\n",
    "    \n",
    "        return self.processState(state)\n",
    "    \n",
    "    def make_step(self, action, render = False):\n",
    "        action = self.processAction(action)\n",
    "    \n",
    "        state, ret1, ret2, ret3 = self.env.step(action)\n",
    "    \n",
    "        if render:\n",
    "            self.env.render()\n",
    "    \n",
    "        return self.processState(state), ret1, ret2, ret3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CartPole_wrapper():\n",
    "    def __init__(self):\n",
    "        self.state_size = (1, 4)\n",
    "        self.game_title = \"CartPole-v0\"\n",
    "        self.actions = [\"LEFT\", \"RIGHT\"]\n",
    "        self.n_actions = len(self.actions)\n",
    "        try:\n",
    "            self.env = gym.make(self.game_title)\n",
    "        except:\n",
    "            print (\"ERROR : Can't find \" + self.game_title + \" environment.\")\n",
    "            return None\n",
    "        self.env.reset()\n",
    "    \n",
    "    def processState(self, state):\n",
    "        return state.reshape(1, -1)\n",
    "    \n",
    "    def processAction(self, action):\n",
    "        return action\n",
    "    \n",
    "    def make_reset(self):\n",
    "        state = self.env.reset()\n",
    "    \n",
    "        return self.processState(state)\n",
    "    \n",
    "    def make_step(self, action, render = False):\n",
    "        action = self.processAction(action)\n",
    "    \n",
    "        state, ret1, ret2, ret3 = self.env.step(action)\n",
    "    \n",
    "        if render:\n",
    "            self.env.render()\n",
    "    \n",
    "        return self.processState(state), ret1, ret2, ret3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AVQ_nn():\n",
    "    def __init__(self, channels_number = 4, image_shape = (1, 8), n_actions = 4, grad_clipping = 10, lr = 0.0001):\n",
    "        self.input_var = T.tensor4('input')\n",
    "        \n",
    "        self.n_actions = n_actions\n",
    "        self.build_network(channels_number, image_shape)\n",
    "        self.build_AVQ(grad_clipping, lr)\n",
    "        self.compile_network()\n",
    "        \n",
    "    def build_network(self, channels_number, image_shape):\n",
    "        self.l1 = lasagne.layers.InputLayer(shape=(None, channels_number, image_shape[0], image_shape[1]), \n",
    "                                            input_var = self.input_var)\n",
    "        self.l2 = lasagne.layers.DenseLayer(self.l1, 40, nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "        self.l3 = lasagne.layers.DenseLayer(self.l2, 40, nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "        self.outlayer = lasagne.layers.DenseLayer(self.l3, 50, nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    def build_AVQ(self, grad_clipping, lr):\n",
    "        self.l_advantage = lasagne.layers.DenseLayer(self.outlayer, self.n_actions)\n",
    "        self.l_value = lasagne.layers.DenseLayer(self.outlayer, 1)\n",
    "        \n",
    "        self.advantage, self.value = lasagne.layers.get_output([self.l_advantage, self.l_value])\n",
    "\n",
    "        self.average_advantage = T.mean(self.advantage, keepdims = True, axis = 1)\n",
    "        \n",
    "#        self.Qout = self.advantage + self.value - self.average_advantage\n",
    "        self.Qout = self.advantage + self.value * 0\n",
    "        self.predict = T.argmax(self.Qout, axis = 1)\n",
    "        \n",
    "        self.targetQ = T.fvector('targetQ')\n",
    "        self.actions = T.ivector('actions')\n",
    "        self.actions_onehot = T.extra_ops.to_one_hot(self.actions, self.n_actions, dtype=np.float32)\n",
    "        \n",
    "        self.Q = T.sum(self.Qout * self.actions_onehot, axis = 1)\n",
    "        \n",
    "        self.td_error = T.sqr(self.targetQ - self.Q)\n",
    "        self.loss = T.mean(self.td_error)\n",
    "        \n",
    "        params = self.get_all_params()\n",
    "        self.all_grads = T.grad(self.loss, params)\n",
    "        self.scaled_grads = lasagne.updates.total_norm_constraint(self.all_grads, grad_clipping)\n",
    "        self.updates = lasagne.updates.adam(self.scaled_grads, params, learning_rate=lr)\n",
    "        \n",
    "    def compile_network(self):\n",
    "        self.Qout_fn = theano.function([self.input_var], self.Qout)\n",
    "        self.actionpred_fn = theano.function([self.input_var], self.predict)\n",
    "        self.train_fn = theano.function([self.input_var, self.targetQ, self.actions], self.loss, updates = self.updates)\n",
    "    \n",
    "    def get_all_params(self):\n",
    "        return lasagne.layers.get_all_params([self.l_advantage, self.l_value], trainable = True)\n",
    "    \n",
    "    def get_all_params_values(self):\n",
    "        return lasagne.layers.get_all_param_values([self.l_advantage, self.l_value], trainable = True)\n",
    "    \n",
    "    def set_all_params_values(self, values):\n",
    "        return lasagne.layers.set_all_param_values([self.l_advantage, self.l_value], values, trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 10000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self, experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self, size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class window_aggregator():\n",
    "    def __init__(self, window_length, state_shape):\n",
    "        self.state_shape = state_shape\n",
    "        self.window_length = window_length\n",
    "        \n",
    "        assert len(self.state_shape) == 2\n",
    "        assert self.window_length >= 1\n",
    "        \n",
    "        self.start_aggregator_shape = (window_length, state_shape[0], state_shape[1])\n",
    "                                             \n",
    "        self.aggregator = np.zeros(self.start_aggregator_shape)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.aggregator = np.zeros(self.start_aggregator_shape)\n",
    "                                       \n",
    "    def add_state(self, state):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        self.aggregator = np.append(self.aggregator, state, axis = 0)\n",
    "    \n",
    "    def get_window(self):\n",
    "        return self.aggregator[-self.window_length:,:,:]                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class egreedy_agent():\n",
    "    def __init__(self, n_actions, actionpred_fn, startE = 1, endE = 0.1, anneling_steps = 50000):\n",
    "        self.startE = startE\n",
    "        self.endE = endE\n",
    "        self.anneling_steps = anneling_steps\n",
    "        self.stepE = (self.startE - self.endE) / self.anneling_steps\n",
    "        self.n_actions = n_actions\n",
    "        self.actionpred_fn = actionpred_fn\n",
    "    \n",
    "    def choose_action(self, state, current_step):\n",
    "        if current_step > self.anneling_steps:\n",
    "            epsilon = self.endE\n",
    "        else:\n",
    "            epsilon = self.startE - self.stepE * current_step\n",
    "        \n",
    "        if np.random.rand(1) < epsilon:\n",
    "            a = np.random.randint(0, self.n_actions)\n",
    "        else:\n",
    "            a = self.actionpred_fn(np.expand_dims(state, axis = 0))[0]\n",
    "            \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class boltzman_agent:\n",
    "    def __init__(self, n_actions, Qout_fn, startT = 1000, endT = 0.1, anneling_steps = 50000):\n",
    "        self.startT = startT\n",
    "        self.endT = endT\n",
    "        self.anneling_steps = anneling_steps\n",
    "        self.logstep = (np.log(startT) - np.log(endT)) / anneling_steps\n",
    "        self.n_actions = n_actions\n",
    "        self.Qout_fn = Qout_fn\n",
    "    \n",
    "    def choose_action(self, state, current_step):\n",
    "        scores = self.Qout_fn(np.expand_dims(state, axis = 0))[0]\n",
    "        if current_step > self.anneling_steps:\n",
    "            exponents = np.exp((scores - np.max(scores)) / self.endT)\n",
    "        else:\n",
    "            current_temp = self.startT / np.exp(self.logstep * current_step)\n",
    "            exponents = np.exp((scores - np.max(scores)) / current_temp)\n",
    "        probs = exponents / np.sum(exponents)\n",
    "        return np.random.choice(self.n_actions, p = probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DDQL():\n",
    "    def __init__(self, lparams, env, agent = {\"agent\":\"egreedy\", \"params\":{}}):\n",
    "        self.grad_clip = lparams[\"grad_clipping\"]\n",
    "        self.lr = lparams[\"learning_rate\"]\n",
    "        self.window_size = lparams[\"window_size\"]\n",
    "        self.batch_size = lparams[\"batch_size\"]\n",
    "        self.gamma = lparams[\"gamma\"]\n",
    "        self.MQN_updatefreq = lparams[\"MQN_updatefreq\"]\n",
    "        self.TQN_updatefreq = lparams[\"TQN_updatefreq\"]\n",
    "        self.TQN_updaterate = lparams[\"TQN_updaterate\"]\n",
    "        self.print_freq = lparams[\"print_freq\"]\n",
    "        self.pretrain_steps = lparams[\"pretrain_steps\"]\n",
    "        self.buffer_size = lparams[\"buffer_size\"]\n",
    "        self.pretrain_over = False\n",
    "        \n",
    "        self.env = env\n",
    "        self.mainQN = AVQ_nn(self.window_size, self.env.state_size, self.env.n_actions, self.grad_clip, self.lr)\n",
    "        self.targetQN = AVQ_nn(self.window_size, self.env.state_size, self.env.n_actions, self.grad_clip, self.lr)\n",
    "\n",
    "        self.jList = []\n",
    "        self.rList = []\n",
    "        self.total_steps = 0\n",
    "        \n",
    "        self.window = window_aggregator(self.window_size, self.env.state_size)\n",
    "        self.experience_storage = experience_buffer(self.buffer_size)\n",
    "        self.agent = self.getAgent(agent[\"agent\"], agent[\"params\"])\n",
    "            \n",
    "    def getAgent(self, agent, agentparams):\n",
    "        if agent == \"egreedy\":\n",
    "            return egreedy_agent(self.env.n_actions, self.mainQN.actionpred_fn, **agentparams)\n",
    "        elif agent == \"boltzman\":\n",
    "            return boltzman_agent(self.env.n_actions, self.mainQN.Qout_fn, **agentparams)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown agent\")\n",
    "            \n",
    "    def updateTarget(self):\n",
    "        self.targetQN.set_all_params_values(self.mainQN.get_all_params_values())\n",
    "    \n",
    "    def discount_rewards(self, r):\n",
    "        return r\n",
    "        \n",
    "        discounted_r = np.zeros_like(r)\n",
    "        running_add = 0\n",
    "        for t in reversed(xrange(0, r.size)):\n",
    "            running_add = running_add * self.gamma + r[t]\n",
    "            discounted_r[t] = running_add\n",
    "        return discounted_r\n",
    "\n",
    "    def train(self, num_episodes, frame_limit, render = True):\n",
    "        self.updateTarget()\n",
    "        self.window.reset()\n",
    "            \n",
    "        for episode_num in tqdm_notebook(range(num_episodes), desc = \"RL train\"):\n",
    "            episode_storage = experience_buffer()\n",
    "            state = self.env.make_reset()\n",
    "            self.window.add_state(state)\n",
    "            window_state = self.window.get_window()\n",
    "                \n",
    "            for iteration in xrange(0, frame_limit):\n",
    "                action = self.agent.choose_action(window_state, self.total_steps)\n",
    "                new_state, reward, gameover, _ = self.env.make_step(action, render)\n",
    "                self.window.add_state(new_state)\n",
    "                new_window_state = self.window.get_window()\n",
    "                episode_storage.add(np.reshape(np.array([window_state, action, reward, new_window_state, gameover]),[1,5]))\n",
    "                    \n",
    "                if self.pretrain_over:\n",
    "                    self.total_steps += 1\n",
    "                \n",
    "                    if self.total_steps % (self.TQN_updatefreq) == 0:\n",
    "                        self.updateTarget()\n",
    "                \n",
    "                    if self.total_steps % (self.MQN_updatefreq) == 0:\n",
    "                        train_batch = self.experience_storage.sample(self.batch_size)\n",
    "                        new_state_batch = np.stack(train_batch[:,3])\n",
    "                        old_state_batch = np.stack(train_batch[:,0])\n",
    "                        Q1 = self.mainQN.actionpred_fn(new_state_batch)   \n",
    "                        Q2 = self.targetQN.Qout_fn(new_state_batch)\n",
    "#                        Q2 = self.mainQN.Qout_fn(new_state_batch)\n",
    "                        end_multiplier = -(train_batch[:,4] - 1)\n",
    "                        doubleQ = Q2[range(self.batch_size),Q1]\n",
    "                        targetQ = (train_batch[:,2] + (self.gamma * doubleQ * end_multiplier)).astype(np.float32)\n",
    "                        action_vector = (train_batch[:,1]).astype(np.int32)\n",
    "                        _ = self.mainQN.train_fn(old_state_batch, targetQ, action_vector)\n",
    "                         \n",
    "                else:\n",
    "                    self.pretrain_steps -= 1;\n",
    "                    if self.pretrain_steps <= 0:\n",
    "                        self.pretrain_over = True\n",
    "                        \n",
    "                state = new_state\n",
    "                window_state = new_window_state\n",
    "            \n",
    "                if gameover:\n",
    "                    self.window.reset()\n",
    "                    break\n",
    "    \n",
    "            episode_rewards = np.array(episode_storage.buffer)[:,2]\n",
    "            total_reward = np.sum(episode_rewards)\n",
    "            discount_rewards = self.discount_rewards(episode_rewards)\n",
    "            buffer_array = np.array(episode_storage.buffer)\n",
    "            buffer_array[:,2] = discount_rewards\n",
    "            self.experience_storage.add(zip(buffer_array))\n",
    "            self.jList.append(iteration)\n",
    "            self.rList.append(total_reward)\n",
    "            if len(self.rList) % self.print_freq == 0:\n",
    "                tqdm.write(\" \".join([\"========= Episode\", str(episode_num), \"================================================\"]))\n",
    "                tqdm.write(\" \".join([\"Total steps:\", str(self.total_steps)]))\n",
    "                tqdm.write(\" \".join([\"Episode rewards, last 10:\", str(self.rList[-10:])]))\n",
    "                tqdm.write(\" \".join([\"Mean over last\", str(self.print_freq), \"episodes:\", str(np.mean(self.rList[-self.print_freq:]))]))\n",
    "                tqdm.write(\" \".join([\"Episode lengths, last 10:\", str(self.jList[-10:])]))\n",
    "                tqdm.write(\"===================================================================\" + \"=\" * len(str(episode_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rewards(ddqlmodel, meanwindow = 250):\n",
    "    rlist = [ddqlmodel.rList[0]] * meanwindow + ddqlmodel.rList\n",
    "    x = [np.mean(rlist[k:k+meanwindow]) for k in range(len(rlist) - meanwindow)]\n",
    "    plt.plot(np.arange(len(x)), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-14 13:26:14,906] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "#ll_env = LunarLanding_wrapper()\n",
    "cp_env = CartPole_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lparams = {\"grad_clipping\" : 50,\n",
    "           \"learning_rate\" : 0.005,\n",
    "           \"window_size\" : 1,\n",
    "           \"batch_size\" : 8,\n",
    "           \"buffer_size\" : 128,\n",
    "           \"gamma\" : 0.98,\n",
    "           \"MQN_updatefreq\" : 1,\n",
    "           \"TQN_updatefreq\" : 16,\n",
    "           \"TQN_updaterate\" : 0.01,\n",
    "           \"print_freq\" : 500,\n",
    "           \"pretrain_steps\" : 5000,\n",
    "           \"render\" : False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "egreedyagentinfo = {\"agent\" : \"egreedy\",\n",
    "                    \"params\" : {\"startE\": 0.5,\n",
    "                                \"endE\" : 0.1,\n",
    "                                \"anneling_steps\":1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boltzmanagentinfo = {\"agent\" : \"boltzman\",\n",
    "                     \"params\" : {\"startT\": 10,\n",
    "                                 \"endT\" : 1,\n",
    "                                 \"anneling_steps\":10000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddql = DDQL(lparams = lparams, env = cp_env, agent = boltzmanagentinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddql.train(num_episodes = 5000, frame_limit = 500, render = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_rewards(ddql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Е-жадная стратегия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddql2 = DDQL(lparams = lparams, env = cp_env, agent = boltzmanagentinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddql2.train(num_episodes = 5000, frame_limit = 500, render = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_rewards(ddql2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Е-жадная стратегия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddql4 = DDQL(lparams = lparams, env = cp_env, agent = boltzmanagentinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddql4.train(num_episodes = 2500, frame_limit = 500, render = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_rewards(ddql4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Как видно из графиков(первые два - е-жадная стратегия, третий - стратегия с сглаживанием больцмана), процесс обучения нестабилен, т.е. алгоритм проводит неопределенное количество времени с маленькой наградой(зависит от начальной инициализации весов и последовательностью сгенерированных эпизодов окружения), только после чего он начинает обучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения наиболее иллюстративных графиков эффектов реализуемых алгоритмов необходимо запускать алгоритм несколько раз (желательно более десяти), и строить графики, показывающие средние значения и средние отклонения наград."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_experiment(ddql, ddql_init_params, ddql_train_params, experiment_num = 5):\n",
    "    ddql_list = [ddql(**ddql_init_params) for k in range(experiment_num)]\n",
    "    \n",
    "    for k in range(experiment_num):\n",
    "        ddql_list[k].train(**ddql_train_params)\n",
    "        \n",
    "    return ddql_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddql_egreedy_params = {\"lparams\":lparams, \"env\":cp_env, \"agent\":egreedyagentinfo}\n",
    "ddql_boltzman_params = {\"lparams\":lparams, \"env\":cp_env, \"agent\":boltzmanagentinfo}\n",
    "\n",
    "ddql_train_params = {\"num_episodes\":2500, \"frame_limit\":500, \"render\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 1448\n",
      "Episode rewards, last 10: [10.0, 9.0, 9.0, 8.0, 12.0, 10.0, 9.0, 11.0, 9.0, 9.0]\n",
      "Mean over last 500 episodes: 12.896\n",
      "Episode lengths, last 10: [9, 8, 8, 7, 11, 9, 8, 10, 8, 8]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 83980\n",
      "Episode rewards, last 10: [500.0, 500.0, 84.0, 103.0, 53.0, 183.0, 500.0, 52.0, 10.0, 22.0]\n",
      "Mean over last 500 episodes: 165.064\n",
      "Episode lengths, last 10: [499, 499, 83, 102, 52, 182, 499, 51, 9, 21]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 185461\n",
      "Episode rewards, last 10: [152.0, 380.0, 126.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 202.962\n",
      "Episode lengths, last 10: [151, 379, 125, 499, 499, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 294158\n",
      "Episode rewards, last 10: [125.0, 500.0, 35.0, 17.0, 15.0, 500.0, 80.0, 82.0, 215.0, 65.0]\n",
      "Mean over last 500 episodes: 217.394\n",
      "Episode lengths, last 10: [124, 499, 34, 16, 14, 499, 79, 81, 214, 64]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 398970\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 209.624\n",
      "Episode lengths, last 10: [499, 499, 499, 499, 499, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 1509\n",
      "Episode rewards, last 10: [9.0, 11.0, 10.0, 10.0, 9.0, 10.0, 10.0, 13.0, 10.0, 9.0]\n",
      "Mean over last 500 episodes: 13.018\n",
      "Episode lengths, last 10: [8, 10, 9, 9, 8, 9, 9, 12, 9, 8]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 6451\n",
      "Episode rewards, last 10: [8.0, 8.0, 10.0, 9.0, 12.0, 9.0, 10.0, 9.0, 10.0, 8.0]\n",
      "Mean over last 500 episodes: 9.884\n",
      "Episode lengths, last 10: [7, 7, 9, 8, 11, 8, 9, 8, 9, 7]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 11370\n",
      "Episode rewards, last 10: [10.0, 12.0, 9.0, 9.0, 8.0, 10.0, 10.0, 10.0, 11.0, 9.0]\n",
      "Mean over last 500 episodes: 9.838\n",
      "Episode lengths, last 10: [9, 11, 8, 8, 7, 9, 9, 9, 10, 8]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 16298\n",
      "Episode rewards, last 10: [9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 9.0, 10.0]\n",
      "Mean over last 500 episodes: 9.856\n",
      "Episode lengths, last 10: [8, 9, 9, 9, 9, 9, 11, 9, 8, 9]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 21283\n",
      "Episode rewards, last 10: [10.0, 10.0, 9.0, 12.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0]\n",
      "Mean over last 500 episodes: 9.97\n",
      "Episode lengths, last 10: [9, 9, 8, 11, 9, 9, 9, 9, 8, 8]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 15878\n",
      "Episode rewards, last 10: [51.0, 500.0, 238.0, 391.0, 105.0, 13.0, 14.0, 75.0, 166.0, 14.0]\n",
      "Mean over last 500 episodes: 41.756\n",
      "Episode lengths, last 10: [50, 499, 237, 390, 104, 12, 13, 74, 165, 13]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 111539\n",
      "Episode rewards, last 10: [190.0, 106.0, 143.0, 121.0, 284.0, 228.0, 111.0, 209.0, 87.0, 104.0]\n",
      "Mean over last 500 episodes: 191.322\n",
      "Episode lengths, last 10: [189, 105, 142, 120, 283, 227, 110, 208, 86, 103]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 207000\n",
      "Episode rewards, last 10: [451.0, 107.0, 58.0, 500.0, 166.0, 338.0, 137.0, 500.0, 14.0, 470.0]\n",
      "Mean over last 500 episodes: 190.922\n",
      "Episode lengths, last 10: [450, 106, 57, 499, 165, 337, 136, 499, 13, 469]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 304168\n",
      "Episode rewards, last 10: [185.0, 196.0, 500.0, 500.0, 500.0, 500.0, 219.0, 231.0, 202.0, 219.0]\n",
      "Mean over last 500 episodes: 194.336\n",
      "Episode lengths, last 10: [184, 195, 499, 499, 499, 499, 218, 230, 201, 218]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 414862\n",
      "Episode rewards, last 10: [97.0, 128.0, 135.0, 123.0, 17.0, 22.0, 73.0, 39.0, 206.0, 68.0]\n",
      "Mean over last 500 episodes: 221.388\n",
      "Episode lengths, last 10: [96, 127, 134, 122, 16, 21, 72, 38, 205, 67]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 68244\n",
      "Episode rewards, last 10: [500.0, 453.0, 24.0, 122.0, 305.0, 257.0, 391.0, 385.0, 500.0, 64.0]\n",
      "Mean over last 500 episodes: 146.488\n",
      "Episode lengths, last 10: [499, 452, 23, 121, 304, 256, 390, 384, 499, 63]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 173563\n",
      "Episode rewards, last 10: [500.0, 500.0, 46.0, 12.0, 97.0, 116.0, 500.0, 207.0, 289.0, 143.0]\n",
      "Mean over last 500 episodes: 210.638\n",
      "Episode lengths, last 10: [499, 499, 45, 11, 96, 115, 499, 206, 288, 142]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 308744\n",
      "Episode rewards, last 10: [422.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 247.0, 129.0, 123.0]\n",
      "Mean over last 500 episodes: 270.362\n",
      "Episode lengths, last 10: [421, 499, 499, 499, 499, 499, 499, 246, 128, 122]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 439706\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 328.0, 136.0, 79.0, 291.0, 12.0, 13.0, 127.0]\n",
      "Mean over last 500 episodes: 261.924\n",
      "Episode lengths, last 10: [499, 499, 499, 327, 135, 78, 290, 11, 12, 126]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 570095\n",
      "Episode rewards, last 10: [114.0, 500.0, 171.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 260.778\n",
      "Episode lengths, last 10: [113, 499, 170, 499, 499, 499, 499, 499, 499, 499]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 14701\n",
      "Episode rewards, last 10: [77.0, 19.0, 247.0, 397.0, 107.0, 56.0, 335.0, 113.0, 170.0, 500.0]\n",
      "Mean over last 500 episodes: 39.402\n",
      "Episode lengths, last 10: [76, 18, 246, 396, 106, 55, 334, 112, 169, 499]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 104506\n",
      "Episode rewards, last 10: [72.0, 59.0, 331.0, 235.0, 12.0, 145.0, 11.0, 14.0, 52.0, 63.0]\n",
      "Mean over last 500 episodes: 179.61\n",
      "Episode lengths, last 10: [71, 58, 330, 234, 11, 144, 10, 13, 51, 62]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 181129\n",
      "Episode rewards, last 10: [28.0, 27.0, 132.0, 39.0, 39.0, 59.0, 449.0, 60.0, 30.0, 36.0]\n",
      "Mean over last 500 episodes: 153.246\n",
      "Episode lengths, last 10: [27, 26, 131, 38, 38, 58, 448, 59, 29, 35]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 287765\n",
      "Episode rewards, last 10: [500.0, 13.0, 51.0, 15.0, 132.0, 500.0, 500.0, 202.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 213.272\n",
      "Episode lengths, last 10: [499, 12, 50, 14, 131, 499, 499, 201, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 336694\n",
      "Episode rewards, last 10: [9.0, 10.0, 9.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0]\n",
      "Mean over last 500 episodes: 97.858\n",
      "Episode lengths, last 10: [8, 9, 8, 9, 9, 9, 9, 8, 8, 8]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 1599\n",
      "Episode rewards, last 10: [8.0, 10.0, 9.0, 9.0, 8.0, 12.0, 10.0, 9.0, 10.0, 12.0]\n",
      "Mean over last 500 episodes: 13.198\n",
      "Episode lengths, last 10: [7, 9, 8, 8, 7, 11, 9, 8, 9, 11]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 6540\n",
      "Episode rewards, last 10: [14.0, 9.0, 9.0, 11.0, 11.0, 10.0, 10.0, 9.0, 11.0, 9.0]\n",
      "Mean over last 500 episodes: 9.882\n",
      "Episode lengths, last 10: [13, 8, 8, 10, 10, 9, 9, 8, 10, 8]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 11545\n",
      "Episode rewards, last 10: [9.0, 10.0, 10.0, 12.0, 9.0, 10.0, 15.0, 10.0, 12.0, 10.0]\n",
      "Mean over last 500 episodes: 10.01\n",
      "Episode lengths, last 10: [8, 9, 9, 11, 8, 9, 14, 9, 11, 9]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 24863\n",
      "Episode rewards, last 10: [469.0, 315.0, 230.0, 317.0, 16.0, 160.0, 12.0, 24.0, 40.0, 45.0]\n",
      "Mean over last 500 episodes: 26.636\n",
      "Episode lengths, last 10: [468, 314, 229, 316, 15, 159, 11, 23, 39, 44]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 121515\n",
      "Episode rewards, last 10: [391.0, 34.0, 500.0, 287.0, 500.0, 500.0, 337.0, 36.0, 159.0, 166.0]\n",
      "Mean over last 500 episodes: 193.304\n",
      "Episode lengths, last 10: [390, 33, 499, 286, 499, 499, 336, 35, 158, 165]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 29157\n",
      "Episode rewards, last 10: [171.0, 500.0, 500.0, 177.0, 500.0, 81.0, 13.0, 500.0, 500.0, 155.0]\n",
      "Mean over last 500 episodes: 68.314\n",
      "Episode lengths, last 10: [170, 499, 499, 176, 499, 80, 12, 499, 499, 154]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 104185\n",
      "Episode rewards, last 10: [96.0, 143.0, 39.0, 390.0, 500.0, 500.0, 45.0, 280.0, 108.0, 500.0]\n",
      "Mean over last 500 episodes: 150.056\n",
      "Episode lengths, last 10: [95, 142, 38, 389, 499, 499, 44, 279, 107, 499]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 194707\n",
      "Episode rewards, last 10: [365.0, 500.0, 500.0, 500.0, 327.0, 24.0, 500.0, 226.0, 500.0, 59.0]\n",
      "Mean over last 500 episodes: 181.044\n",
      "Episode lengths, last 10: [364, 499, 499, 499, 326, 23, 499, 225, 499, 58]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 297597\n",
      "Episode rewards, last 10: [15.0, 16.0, 41.0, 12.0, 12.0, 10.0, 8.0, 13.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 205.78\n",
      "Episode lengths, last 10: [14, 15, 40, 11, 11, 9, 7, 12, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 410249\n",
      "Episode rewards, last 10: [11.0, 40.0, 45.0, 162.0, 126.0, 86.0, 105.0, 21.0, 17.0, 500.0]\n",
      "Mean over last 500 episodes: 225.304\n",
      "Episode lengths, last 10: [10, 39, 44, 161, 125, 85, 104, 20, 16, 499]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 67544\n",
      "Episode rewards, last 10: [69.0, 273.0, 26.0, 17.0, 152.0, 34.0, 43.0, 96.0, 16.0, 500.0]\n",
      "Mean over last 500 episodes: 145.088\n",
      "Episode lengths, last 10: [68, 272, 25, 16, 151, 33, 42, 95, 15, 499]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 181095\n",
      "Episode rewards, last 10: [500.0, 413.0, 500.0, 116.0, 183.0, 14.0, 110.0, 119.0, 123.0, 107.0]\n",
      "Mean over last 500 episodes: 227.102\n",
      "Episode lengths, last 10: [499, 412, 499, 115, 182, 13, 109, 118, 122, 106]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 305285\n",
      "Episode rewards, last 10: [103.0, 139.0, 147.0, 150.0, 500.0, 86.0, 206.0, 65.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 248.38\n",
      "Episode lengths, last 10: [102, 138, 146, 149, 499, 85, 205, 64, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 435281\n",
      "Episode rewards, last 10: [67.0, 34.0, 36.0, 28.0, 88.0, 37.0, 35.0, 33.0, 31.0, 57.0]\n",
      "Mean over last 500 episodes: 259.992\n",
      "Episode lengths, last 10: [66, 33, 35, 27, 87, 36, 34, 32, 30, 56]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 565740\n",
      "Episode rewards, last 10: [14.0, 129.0, 148.0, 500.0, 13.0, 17.0, 14.0, 101.0, 47.0, 173.0]\n",
      "Mean over last 500 episodes: 260.918\n",
      "Episode lengths, last 10: [13, 128, 147, 499, 12, 16, 13, 100, 46, 172]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 69828\n",
      "Episode rewards, last 10: [10.0, 16.0, 12.0, 14.0, 79.0, 90.0, 80.0, 500.0, 13.0, 50.0]\n",
      "Mean over last 500 episodes: 149.656\n",
      "Episode lengths, last 10: [9, 15, 11, 13, 78, 89, 79, 499, 12, 49]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 161921\n",
      "Episode rewards, last 10: [153.0, 217.0, 194.0, 37.0, 154.0, 443.0, 299.0, 136.0, 500.0, 80.0]\n",
      "Mean over last 500 episodes: 184.186\n",
      "Episode lengths, last 10: [152, 216, 193, 36, 153, 442, 298, 135, 499, 79]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 259505\n",
      "Episode rewards, last 10: [500.0, 500.0, 500.0, 500.0, 500.0, 30.0, 28.0, 500.0, 156.0, 500.0]\n",
      "Mean over last 500 episodes: 195.168\n",
      "Episode lengths, last 10: [499, 499, 499, 499, 499, 29, 27, 499, 155, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 383200\n",
      "Episode rewards, last 10: [100.0, 62.0, 500.0, 100.0, 25.0, 69.0, 461.0, 108.0, 500.0, 500.0]\n",
      "Mean over last 500 episodes: 247.39\n",
      "Episode lengths, last 10: [99, 61, 499, 99, 24, 68, 460, 107, 499, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 509272\n",
      "Episode rewards, last 10: [82.0, 78.0, 82.0, 141.0, 79.0, 296.0, 500.0, 61.0, 90.0, 89.0]\n",
      "Mean over last 500 episodes: 252.144\n",
      "Episode lengths, last 10: [81, 77, 81, 140, 78, 295, 499, 60, 89, 88]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 2133\n",
      "Episode rewards, last 10: [10.0, 8.0, 9.0, 11.0, 9.0, 9.0, 9.0, 10.0, 10.0, 8.0]\n",
      "Mean over last 500 episodes: 14.266\n",
      "Episode lengths, last 10: [9, 7, 8, 10, 8, 8, 8, 9, 9, 7]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 7087\n",
      "Episode rewards, last 10: [10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 10.0, 9.0, 10.0, 13.0]\n",
      "Mean over last 500 episodes: 9.908\n",
      "Episode lengths, last 10: [9, 9, 9, 9, 8, 8, 9, 8, 9, 12]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 12023\n",
      "Episode rewards, last 10: [10.0, 9.0, 10.0, 10.0, 11.0, 11.0, 9.0, 10.0, 9.0, 8.0]\n",
      "Mean over last 500 episodes: 9.872\n",
      "Episode lengths, last 10: [9, 8, 9, 9, 10, 10, 8, 9, 8, 7]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 16946\n",
      "Episode rewards, last 10: [10.0, 10.0, 10.0, 9.0, 9.0, 8.0, 8.0, 10.0, 9.0, 10.0]\n",
      "Mean over last 500 episodes: 9.846\n",
      "Episode lengths, last 10: [9, 9, 9, 8, 8, 7, 7, 9, 8, 9]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 21873\n",
      "Episode rewards, last 10: [9.0, 9.0, 12.0, 10.0, 10.0, 9.0, 10.0, 11.0, 10.0, 10.0]\n",
      "Mean over last 500 episodes: 9.854\n",
      "Episode lengths, last 10: [8, 8, 11, 9, 9, 8, 9, 10, 9, 9]\n",
      "=======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = produce_experiment(DDQL, ddql_egreedy_params, ddql_train_params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Episode 499 ================================================\n",
      "Total steps: 24039\n",
      "Episode rewards, last 10: [15.0, 131.0, 48.0, 102.0, 106.0, 125.0, 113.0, 29.0, 168.0, 120.0]\n",
      "Mean over last 500 episodes: 58.078\n",
      "Episode lengths, last 10: [14, 130, 47, 101, 105, 124, 112, 28, 167, 119]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 94540\n",
      "Episode rewards, last 10: [165.0, 20.0, 166.0, 37.0, 366.0, 52.0, 282.0, 273.0, 26.0, 199.0]\n",
      "Mean over last 500 episodes: 141.002\n",
      "Episode lengths, last 10: [164, 19, 165, 36, 365, 51, 281, 272, 25, 198]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 169234\n",
      "Episode rewards, last 10: [143.0, 55.0, 107.0, 17.0, 48.0, 16.0, 91.0, 87.0, 151.0, 144.0]\n",
      "Mean over last 500 episodes: 149.388\n",
      "Episode lengths, last 10: [142, 54, 106, 16, 47, 15, 90, 86, 150, 143]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 250590\n",
      "Episode rewards, last 10: [135.0, 69.0, 500.0, 109.0, 32.0, 75.0, 65.0, 129.0, 45.0, 25.0]\n",
      "Mean over last 500 episodes: 162.712\n",
      "Episode lengths, last 10: [134, 68, 499, 108, 31, 74, 64, 128, 44, 24]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 337202\n",
      "Episode rewards, last 10: [500.0, 217.0, 138.0, 30.0, 228.0, 291.0, 20.0, 58.0, 355.0, 32.0]\n",
      "Mean over last 500 episodes: 173.224\n",
      "Episode lengths, last 10: [499, 216, 137, 29, 227, 290, 19, 57, 354, 31]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 23842\n",
      "Episode rewards, last 10: [132.0, 220.0, 322.0, 31.0, 26.0, 500.0, 297.0, 174.0, 490.0, 355.0]\n",
      "Mean over last 500 episodes: 57.684\n",
      "Episode lengths, last 10: [131, 219, 321, 30, 25, 499, 296, 173, 489, 354]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 92094\n",
      "Episode rewards, last 10: [458.0, 65.0, 71.0, 85.0, 18.0, 87.0, 44.0, 11.0, 50.0, 124.0]\n",
      "Mean over last 500 episodes: 136.504\n",
      "Episode lengths, last 10: [457, 64, 70, 84, 17, 86, 43, 10, 49, 123]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 169413\n",
      "Episode rewards, last 10: [111.0, 181.0, 20.0, 21.0, 28.0, 287.0, 70.0, 250.0, 197.0, 164.0]\n",
      "Mean over last 500 episodes: 154.638\n",
      "Episode lengths, last 10: [110, 180, 19, 20, 27, 286, 69, 249, 196, 163]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 243552\n",
      "Episode rewards, last 10: [304.0, 299.0, 224.0, 106.0, 225.0, 24.0, 15.0, 15.0, 17.0, 18.0]\n",
      "Mean over last 500 episodes: 148.278\n",
      "Episode lengths, last 10: [303, 298, 223, 105, 224, 23, 14, 14, 16, 17]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 324512\n",
      "Episode rewards, last 10: [112.0, 274.0, 493.0, 490.0, 52.0, 54.0, 102.0, 257.0, 314.0, 21.0]\n",
      "Mean over last 500 episodes: 161.92\n",
      "Episode lengths, last 10: [111, 273, 492, 489, 51, 53, 101, 256, 313, 20]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 29860\n",
      "Episode rewards, last 10: [278.0, 48.0, 150.0, 102.0, 212.0, 303.0, 13.0, 190.0, 219.0, 65.0]\n",
      "Mean over last 500 episodes: 69.72\n",
      "Episode lengths, last 10: [277, 47, 149, 101, 211, 302, 12, 189, 218, 64]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 103761\n",
      "Episode rewards, last 10: [73.0, 35.0, 122.0, 23.0, 200.0, 119.0, 233.0, 397.0, 104.0, 20.0]\n",
      "Mean over last 500 episodes: 147.802\n",
      "Episode lengths, last 10: [72, 34, 121, 22, 199, 118, 232, 396, 103, 19]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 171740\n",
      "Episode rewards, last 10: [205.0, 340.0, 192.0, 403.0, 306.0, 90.0, 113.0, 500.0, 366.0, 500.0]\n",
      "Mean over last 500 episodes: 135.958\n",
      "Episode lengths, last 10: [204, 339, 191, 402, 305, 89, 112, 499, 365, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 248101\n",
      "Episode rewards, last 10: [24.0, 63.0, 28.0, 59.0, 71.0, 18.0, 158.0, 160.0, 223.0, 173.0]\n",
      "Mean over last 500 episodes: 152.722\n",
      "Episode lengths, last 10: [23, 62, 27, 58, 70, 17, 157, 159, 222, 172]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 337323\n",
      "Episode rewards, last 10: [209.0, 500.0, 294.0, 258.0, 85.0, 68.0, 188.0, 33.0, 17.0, 500.0]\n",
      "Mean over last 500 episodes: 178.444\n",
      "Episode lengths, last 10: [208, 499, 293, 257, 84, 67, 187, 32, 16, 499]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 26592\n",
      "Episode rewards, last 10: [35.0, 22.0, 32.0, 30.0, 75.0, 184.0, 190.0, 244.0, 500.0, 103.0]\n",
      "Mean over last 500 episodes: 63.184\n",
      "Episode lengths, last 10: [34, 21, 31, 29, 74, 183, 189, 243, 499, 102]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 100381\n",
      "Episode rewards, last 10: [12.0, 500.0, 414.0, 47.0, 44.0, 500.0, 309.0, 20.0, 109.0, 78.0]\n",
      "Mean over last 500 episodes: 147.578\n",
      "Episode lengths, last 10: [11, 499, 413, 46, 43, 499, 308, 19, 108, 77]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 172626\n",
      "Episode rewards, last 10: [199.0, 60.0, 111.0, 147.0, 173.0, 119.0, 100.0, 20.0, 500.0, 16.0]\n",
      "Mean over last 500 episodes: 144.49\n",
      "Episode lengths, last 10: [198, 59, 110, 146, 172, 118, 99, 19, 499, 15]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 251088\n",
      "Episode rewards, last 10: [84.0, 234.0, 34.0, 57.0, 115.0, 500.0, 62.0, 48.0, 500.0, 385.0]\n",
      "Mean over last 500 episodes: 156.924\n",
      "Episode lengths, last 10: [83, 233, 33, 56, 114, 499, 61, 47, 499, 384]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 330868\n",
      "Episode rewards, last 10: [19.0, 14.0, 105.0, 25.0, 84.0, 199.0, 30.0, 85.0, 95.0, 258.0]\n",
      "Mean over last 500 episodes: 159.56\n",
      "Episode lengths, last 10: [18, 13, 104, 24, 83, 198, 29, 84, 94, 257]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 29224\n",
      "Episode rewards, last 10: [500.0, 14.0, 99.0, 500.0, 45.0, 188.0, 200.0, 292.0, 148.0, 112.0]\n",
      "Mean over last 500 episodes: 68.448\n",
      "Episode lengths, last 10: [499, 13, 98, 499, 44, 187, 199, 291, 147, 111]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 101749\n",
      "Episode rewards, last 10: [70.0, 174.0, 155.0, 116.0, 86.0, 48.0, 117.0, 236.0, 99.0, 60.0]\n",
      "Mean over last 500 episodes: 145.05\n",
      "Episode lengths, last 10: [69, 173, 154, 115, 85, 47, 116, 235, 98, 59]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 173646\n",
      "Episode rewards, last 10: [161.0, 60.0, 112.0, 261.0, 17.0, 391.0, 335.0, 26.0, 16.0, 235.0]\n",
      "Mean over last 500 episodes: 143.794\n",
      "Episode lengths, last 10: [160, 59, 111, 260, 16, 390, 334, 25, 15, 234]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 256250\n",
      "Episode rewards, last 10: [297.0, 28.0, 21.0, 15.0, 135.0, 176.0, 160.0, 76.0, 16.0, 40.0]\n",
      "Mean over last 500 episodes: 165.208\n",
      "Episode lengths, last 10: [296, 27, 20, 14, 134, 175, 159, 75, 15, 39]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 338203\n",
      "Episode rewards, last 10: [80.0, 89.0, 90.0, 78.0, 70.0, 52.0, 26.0, 107.0, 136.0, 166.0]\n",
      "Mean over last 500 episodes: 163.906\n",
      "Episode lengths, last 10: [79, 88, 89, 77, 69, 51, 25, 106, 135, 165]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 28662\n",
      "Episode rewards, last 10: [35.0, 107.0, 49.0, 203.0, 187.0, 145.0, 178.0, 187.0, 290.0, 19.0]\n",
      "Mean over last 500 episodes: 67.324\n",
      "Episode lengths, last 10: [34, 106, 48, 202, 186, 144, 177, 186, 289, 18]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 104010\n",
      "Episode rewards, last 10: [13.0, 258.0, 53.0, 28.0, 17.0, 64.0, 94.0, 144.0, 23.0, 111.0]\n",
      "Mean over last 500 episodes: 150.696\n",
      "Episode lengths, last 10: [12, 257, 52, 27, 16, 63, 93, 143, 22, 110]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 177567\n",
      "Episode rewards, last 10: [500.0, 325.0, 18.0, 248.0, 500.0, 14.0, 11.0, 17.0, 16.0, 18.0]\n",
      "Mean over last 500 episodes: 147.114\n",
      "Episode lengths, last 10: [499, 324, 17, 247, 499, 13, 10, 16, 15, 17]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 258366\n",
      "Episode rewards, last 10: [11.0, 9.0, 188.0, 67.0, 97.0, 79.0, 83.0, 86.0, 76.0, 100.0]\n",
      "Mean over last 500 episodes: 161.598\n",
      "Episode lengths, last 10: [10, 8, 187, 66, 96, 78, 82, 85, 75, 99]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 345681\n",
      "Episode rewards, last 10: [212.0, 500.0, 500.0, 111.0, 48.0, 167.0, 120.0, 25.0, 12.0, 15.0]\n",
      "Mean over last 500 episodes: 174.63\n",
      "Episode lengths, last 10: [211, 499, 499, 110, 47, 166, 119, 24, 11, 14]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 24197\n",
      "Episode rewards, last 10: [17.0, 38.0, 17.0, 23.0, 37.0, 133.0, 265.0, 268.0, 155.0, 170.0]\n",
      "Mean over last 500 episodes: 58.394\n",
      "Episode lengths, last 10: [16, 37, 16, 22, 36, 132, 264, 267, 154, 169]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 97989\n",
      "Episode rewards, last 10: [83.0, 500.0, 75.0, 366.0, 29.0, 16.0, 42.0, 500.0, 495.0, 303.0]\n",
      "Mean over last 500 episodes: 147.584\n",
      "Episode lengths, last 10: [82, 499, 74, 365, 28, 15, 41, 499, 494, 302]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 171147\n",
      "Episode rewards, last 10: [23.0, 12.0, 500.0, 500.0, 62.0, 490.0, 51.0, 54.0, 72.0, 147.0]\n",
      "Mean over last 500 episodes: 146.316\n",
      "Episode lengths, last 10: [22, 11, 499, 499, 61, 489, 50, 53, 71, 146]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 251089\n",
      "Episode rewards, last 10: [322.0, 73.0, 22.0, 84.0, 362.0, 180.0, 218.0, 500.0, 500.0, 83.0]\n",
      "Mean over last 500 episodes: 159.884\n",
      "Episode lengths, last 10: [321, 72, 21, 83, 361, 179, 217, 499, 499, 82]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 336557\n",
      "Episode rewards, last 10: [134.0, 500.0, 84.0, 293.0, 111.0, 159.0, 59.0, 21.0, 42.0, 115.0]\n",
      "Mean over last 500 episodes: 170.936\n",
      "Episode lengths, last 10: [133, 499, 83, 292, 110, 158, 58, 20, 41, 114]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 29947\n",
      "Episode rewards, last 10: [133.0, 143.0, 71.0, 44.0, 135.0, 117.0, 65.0, 29.0, 129.0, 500.0]\n",
      "Mean over last 500 episodes: 69.894\n",
      "Episode lengths, last 10: [132, 142, 70, 43, 134, 116, 64, 28, 128, 499]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 102379\n",
      "Episode rewards, last 10: [82.0, 71.0, 80.0, 172.0, 114.0, 71.0, 77.0, 131.0, 500.0, 178.0]\n",
      "Mean over last 500 episodes: 144.864\n",
      "Episode lengths, last 10: [81, 70, 79, 171, 113, 70, 76, 130, 499, 177]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 185826\n",
      "Episode rewards, last 10: [68.0, 34.0, 97.0, 15.0, 500.0, 71.0, 104.0, 21.0, 63.0, 500.0]\n",
      "Mean over last 500 episodes: 166.894\n",
      "Episode lengths, last 10: [67, 33, 96, 14, 499, 70, 103, 20, 62, 499]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 266059\n",
      "Episode rewards, last 10: [167.0, 39.0, 500.0, 347.0, 14.0, 17.0, 11.0, 500.0, 256.0, 500.0]\n",
      "Mean over last 500 episodes: 160.466\n",
      "Episode lengths, last 10: [166, 38, 499, 346, 13, 16, 10, 499, 255, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 349787\n",
      "Episode rewards, last 10: [500.0, 500.0, 71.0, 338.0, 83.0, 313.0, 66.0, 65.0, 270.0, 63.0]\n",
      "Mean over last 500 episodes: 167.456\n",
      "Episode lengths, last 10: [499, 499, 70, 337, 82, 312, 65, 64, 269, 62]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 25497\n",
      "Episode rewards, last 10: [37.0, 500.0, 143.0, 500.0, 251.0, 330.0, 113.0, 136.0, 11.0, 45.0]\n",
      "Mean over last 500 episodes: 60.994\n",
      "Episode lengths, last 10: [36, 499, 142, 499, 250, 329, 112, 135, 10, 44]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 90305\n",
      "Episode rewards, last 10: [394.0, 291.0, 82.0, 184.0, 340.0, 227.0, 264.0, 157.0, 16.0, 19.0]\n",
      "Mean over last 500 episodes: 129.616\n",
      "Episode lengths, last 10: [393, 290, 81, 183, 339, 226, 263, 156, 15, 18]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 160913\n",
      "Episode rewards, last 10: [67.0, 41.0, 75.0, 53.0, 192.0, 16.0, 63.0, 61.0, 171.0, 168.0]\n",
      "Mean over last 500 episodes: 141.216\n",
      "Episode lengths, last 10: [66, 40, 74, 52, 191, 15, 62, 60, 170, 167]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 230003\n",
      "Episode rewards, last 10: [129.0, 133.0, 17.0, 105.0, 497.0, 65.0, 91.0, 57.0, 39.0, 500.0]\n",
      "Mean over last 500 episodes: 138.18\n",
      "Episode lengths, last 10: [128, 132, 16, 104, 496, 64, 90, 56, 38, 499]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 315097\n",
      "Episode rewards, last 10: [123.0, 333.0, 115.0, 41.0, 17.0, 500.0, 180.0, 261.0, 212.0, 127.0]\n",
      "Mean over last 500 episodes: 170.188\n",
      "Episode lengths, last 10: [122, 332, 114, 40, 16, 499, 179, 260, 211, 126]\n",
      "=======================================================================\n",
      "\n",
      "========= Episode 499 ================================================\n",
      "Total steps: 27482\n",
      "Episode rewards, last 10: [57.0, 46.0, 121.0, 176.0, 113.0, 186.0, 500.0, 471.0, 73.0, 50.0]\n",
      "Mean over last 500 episodes: 64.964\n",
      "Episode lengths, last 10: [56, 45, 120, 175, 112, 185, 499, 470, 72, 49]\n",
      "======================================================================\n",
      "========= Episode 999 ================================================\n",
      "Total steps: 103509\n",
      "Episode rewards, last 10: [35.0, 12.0, 88.0, 9.0, 11.0, 44.0, 500.0, 75.0, 191.0, 383.0]\n",
      "Mean over last 500 episodes: 152.054\n",
      "Episode lengths, last 10: [34, 11, 87, 8, 10, 43, 499, 74, 190, 382]\n",
      "======================================================================\n",
      "========= Episode 1499 ================================================\n",
      "Total steps: 184092\n",
      "Episode rewards, last 10: [61.0, 198.0, 15.0, 67.0, 83.0, 332.0, 291.0, 276.0, 235.0, 55.0]\n",
      "Mean over last 500 episodes: 161.166\n",
      "Episode lengths, last 10: [60, 197, 14, 66, 82, 331, 290, 275, 234, 54]\n",
      "=======================================================================\n",
      "========= Episode 1999 ================================================\n",
      "Total steps: 269516\n",
      "Episode rewards, last 10: [12.0, 27.0, 52.0, 102.0, 77.0, 63.0, 86.0, 71.0, 49.0, 59.0]\n",
      "Mean over last 500 episodes: 170.848\n",
      "Episode lengths, last 10: [11, 26, 51, 101, 76, 62, 85, 70, 48, 58]\n",
      "=======================================================================\n",
      "========= Episode 2499 ================================================\n",
      "Total steps: 357072\n",
      "Episode rewards, last 10: [141.0, 107.0, 191.0, 94.0, 266.0, 93.0, 163.0, 47.0, 19.0, 55.0]\n",
      "Mean over last 500 episodes: 175.112\n",
      "Episode lengths, last 10: [140, 106, 190, 93, 265, 92, 162, 46, 18, 54]\n",
      "=======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_b = produce_experiment(DDQL, ddql_boltzman_params, ddql_train_params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_results(ddql_res, window = 100, std_coef = 0.2, results_over = 1000, save = False):\n",
    "    res_lists = [k.rList for k in ddql_res]\n",
    "    res_lists = np.array(res_lists)\n",
    "    pd.DataFrame(data = res_lists)\n",
    "    mean = res_lists.mean(axis = 0)\n",
    "    std = res_lists.std(axis = 0)\n",
    "    rol_mean = np.nan_to_num(pd.Series(mean).rolling(window = window).mean())\n",
    "    rol_std = np.nan_to_num(pd.Series(std).rolling(window = window).mean())\n",
    "    plt.figure()\n",
    "    index = np.arange(len(rol_mean))\n",
    "    plt.plot(index, rol_mean)\n",
    "    plt.fill_between(index, rol_mean-std_coef*rol_std, rol_mean+std_coef*rol_std, color='b', alpha=0.1)\n",
    "    return max(rol_mean[0:results_over]), rol_mean[0:results_over].mean(), pd.DataFrame(data = res_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1432c35d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "greedy_max, greedy_auc, greedy_df = plot_results(res, 100, 0.2)\n",
    "plt.savefig(\"egreedy_cp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1383094d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boltzman_max, boltzman_auc, boltzman_df = plot_results(res_b, 100, 0.2)\n",
    "plt.savefig(\"boltzman_cp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.305 90.360614\n",
      "150.301 95.513982\n"
     ]
    }
   ],
   "source": [
    "print egreedy_max, greedy_auc\n",
    "print boltzman_max, boltzman_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "greedy_df.to_csv(\"greedy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boltzman_df.to_csv(\"boltzman.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "0a2a7d9eee1c4c81b18348320fc40679": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "20978296fa864c668bb03daa719edc9e": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "36503b7a329c4a9aa79291d23a53e3df": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "36a3bb7a701b40599fd97fcd22fc178c": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "3b28b538180a4839b1b2859a2c1d5cfb": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "3ce36271c4014d54a75d0a35b7bbb348": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "4f8a2da01ee94cc2905d18377b43d154": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "5e9c7af3626e4d549e61ec15f83d4724": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "68e599c90db34f7186e79e22dbaa858c": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "7093d295b95e476a858fd3751b20d32c": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "759f13f964a6475aa3ceb503825b0dc9": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "76d7ef3d0dc546889f79be3e6e8011d5": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "7ca1422dbb034c20ba684d9d18b9f41a": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "8651f952b2cc4a12b97ca6640deead9b": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "8e00bd53e82840c49250eaae0d193695": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "96d06379531e49059938d5fdc8b44bf6": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "9a3ed82163d7449db7bed50a0b995a92": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "ae2c29fe73a242cd9a506614025a1fa9": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "b56443463bb64abda09f1ca285688ec3": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "bb44b24139d2412290902ee461c64d84": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "c5fca96b0bb04d7cb37ee05acacb8385": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "ceee4fac4a6640e2b5d36ed33556b66c": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    },
    "cf5f6c2df1634d1b808a552fe88c4563": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    },
    "e3d8249fa89846f5b34a6eade2db50a6": {
     "views": [
      {
       "cell_index": 36
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
